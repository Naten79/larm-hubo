#!/usr/bin/python3
import rclpy
import time
import math
import pyrealsense2 as rs
from rclpy.node import Node
from geometry_msgs.msg import Twist
from sensor_msgs.msg import Image
import signal, numpy as np
import sys, cv2
import numpy as np
import matplotlib.pyplot as plt
from std_msgs.msg import String
from kobuki_ros_interfaces.msg import Sound
from ultralytics import YOLO
from cv_bridge import CvBridge

model = YOLO("/home/s2c7/ros_space/larm-hubo/ia_image_detection/runs/detect/train5/weights/last.pt")
threshold = 0.5

isOk=True
# Node processes:
def mainFunction(args=None):
    # Initialize ROS Node connected to the camera
    rclpy.init(args=args)
    rosNode= Node( "RealSense_driver" )
    camera= Realsense()
    camera.initializeROSNode( rosNode )

    # Start infinite loop
    while isOk:
        camera.read_imgs()
        rclpy.spin_once(rosNode, timeout_sec=0.001)

    # Clean end
    camera.disconnect()
    rosNode.destroy_node()
    rclpy.shutdown()

def signalInteruption(signum, frame):
            global isOk
            print( "\nCtrl-c pressed" )
            isOk= False

# Realsense Node:
class Realsense():
    def __init__(self, fps= 60):
        self.pip=rs.pipeline()
        self.msg1 = String()
        self.image_cv2=np.asanyarray([])
        self.config=rs.config()
        self.bridge=CvBridge()
        self.bridge1=CvBridge()
        self.color_image=np.asanyarray([])
        self.sound=Sound()
        self.sound._value=4
        self.config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 60)
        self.config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 60)
        self.depth_frame = ""
        self.pip.start(self.config)

        count= 1
        refTime= time.process_time()
        freq= 60
        # Connect the camera

    def initializeROSNode( self, aROSNode ):
        self._pubImg=aROSNode.create_publisher(Image,'sensor_msgs/image',10)
        self._timer1=aROSNode.create_timer(0.1,self.traitement_image)
        self._publisher1=aROSNode.create_publisher(String,'detection',10)
        self._publisher=aROSNode.create_publisher(Sound,'/commands/sound',10)

    def read_imgs(self):
        frames = self.pip.wait_for_frames()
        align_to = rs.stream.color
        align = rs.align(align_to)
        aligned_frames =  align.process(frames)

        color_frame = aligned_frames.first(rs.stream.color)
        #color_frame = frames.first(rs.stream.color)
        self.depth_frame = aligned_frames.get_depth_frame()

        # Convert images to numpy arrays
        self.color_image = np.asanyarray(color_frame.get_data())
        

    def disconnect(self):
        print("\nEnding...")
        self.pip.stop()

    def traitement_image(self):
        frame = self.color_image 
        image_width = frame.shape[1]
        image_height = frame.shape[0]
        half_image_width = image_width / 2
        half_image_height = image_height / 2

        results = model(frame)[0]
        for result in results.boxes.data.tolist():
            x1, y1, x2, y2, score, class_id = result
            if score > threshold:
                if int(class_id) == 0:
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                    cv2.putText(frame, results.names[int(class_id)].upper(), 
                                (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
                    x = (x1 + x2) / 2
                    y = (y1 + y2) / 2
                    d = 15 + self.depth_frame.get_distance(int(x), int(y))
                    fov_x = 69.4  
                    horizontal_pixel_distance = x - half_image_width
                    alpha = math.atan(horizontal_pixel_distance * math.tan(math.radians(fov_x / 2)) / half_image_width)

                    self.msg1.data = str(d) + str(alpha)
            
                    print(self.msg1)
                    self._publisher1.publish(self.msg1)
                    self._publisher.publish(self.sound)
        msg_image = self.bridge.cv2_to_imgmsg(frame,"bgr8")
        self._pubImg.publish(msg_image)

        # Display the images or further processing
        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)
        cv2.imshow("1", frame)
        cv2.waitKey(1)
                    
# Go:
if __name__ == '__main__' :
    mainFunction()

